{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import cProfile\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Tensorflow eager exectuion needs to be enabled.<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. Load the data.<h1>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portuguese to English. Schooner does not have a common path for SSL certificate. Thus it is requested to download it mannually first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True,download=False,data_dir=\"/home/adbadre/tensorflow_datasets/\")\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2. Tokenize the data.<h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform words in machine readable format: My name is Adrien. ---> ['my', 'na','me','is','Adr','ien',\".\"] ---> [880,8522,2222,85,'8466','12','8521',0...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "     (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8087"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8214"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_pt.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence With delimiters: Start and end\n",
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "\n",
    "    return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max number of token to have a fix number of features. Fake ex: \"Hello\"-->[5,8,3,0,0,0...,0] and size 40\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 3. Create datasets for learning.<h1>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE,([None],[40]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE,([None],[40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=622986, shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: id=622987, shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 4. Positional Encodding.<h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each token is embedded in a vector of size n. However, the networks needs a sense of 'position' for each token , since it matters here. Thus, a position encoding is added to each dimension of the vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b6598804f60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 5. Masking.<h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important part of the transformer.Masks allows the network to 1) focus on the right part of the input tokens to train ---> padding mask 2) mask the part that need to be predicted during the training ---> look-ahead mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=623003, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=623019, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 6. Scaled Dot Product Attention and Multi Head Attention.<h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell constains the code for the attention product among the heads in transformers. Each head contains depth=Encoding_size//num_heads_multi dimensions of encoding. It allows the model to compute more in parrallel.\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  nb: depth=Encoding_size//num_heads_multi\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "    #print(\"Coucou0:\",q.shape)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    print(\"Coucou1:\",matmul_qk)\n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk #/ tf.math.sqrt(dk)\n",
    "    print(scaled_attention_logits.shape)\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        print(mask.shape)\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "        print(scaled_attention_logits.shape,scaled_attention_logits)\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "    #print(\"Coucou2:\",attention_weights.shape)\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_heads( x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, 2, 10//2))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v,batch_size):\n",
    "    q=split_heads( q, batch_size)\n",
    "    k=split_heads( k, batch_size)\n",
    "    v=split_heads( v, batch_size)\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(tf.random.uniform((2, 5)), tf.random.uniform((2,5)))\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, combined_mask)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn.shape)\n",
    "    print ('Output is:')\n",
    "    print (temp_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.68121254 0.59078825 0.25541353 0.25627518 0.33704412 0.48741806\n",
      "   0.6281066  0.18117249 0.2691809  0.05804956]\n",
      "  [0.15976095 0.8533579  0.7923213  0.4650135  0.6051909  0.47978926\n",
      "   0.45342112 0.77171755 0.20534515 0.8935585 ]\n",
      "  [0.52167416 0.6024835  0.8030534  0.8378202  0.49565768 0.3090304\n",
      "   0.44577014 0.05659437 0.7606263  0.27020216]\n",
      "  [0.6981547  0.53006005 0.22907174 0.16822374 0.30689967 0.65548456\n",
      "   0.754681   0.00303864 0.8861331  0.2946664 ]\n",
      "  [0.90246606 0.5658637  0.87575054 0.25133216 0.48162103 0.57957935\n",
      "   0.87933445 0.5734854  0.32044983 0.55466735]]\n",
      "\n",
      " [[0.42803073 0.00203907 0.3585745  0.57353115 0.17774034 0.16188323\n",
      "   0.6419151  0.5819484  0.40438747 0.60522735]\n",
      "  [0.8858521  0.18687081 0.01288319 0.04826677 0.8481363  0.5129862\n",
      "   0.9011798  0.86810064 0.64729214 0.7717999 ]\n",
      "  [0.2905841  0.3933642  0.25136924 0.2158786  0.07070589 0.34938455\n",
      "   0.339512   0.101354   0.13799798 0.1793909 ]\n",
      "  [0.2239201  0.37771058 0.72612786 0.7802303  0.62457824 0.81498456\n",
      "   0.4498831  0.7236215  0.75362    0.43671584]\n",
      "  [0.18876028 0.500157   0.67845035 0.48260033 0.13765347 0.7245072\n",
      "   0.752928   0.8699981  0.59775174 0.6984559 ]]], shape=(2, 5, 10), dtype=float32)\n",
      "Coucou1: tf.Tensor(\n",
      "[[[[1.0575931  1.138502   1.2981929  0.9938033  1.3994931 ]\n",
      "   [1.138502   1.9640099  1.9233187  1.0093265  1.7292845 ]\n",
      "   [1.2981929  1.9233187  2.2276442  1.1605769  1.9642816 ]\n",
      "   [0.9938033  1.0093265  1.1605769  0.94334406 1.3207018 ]\n",
      "   [1.3994931  1.7292845  1.9642816  1.3207018  2.1967125 ]]\n",
      "\n",
      "  [[0.7407458  0.76561445 0.66130275 1.049701   1.0571702 ]\n",
      "   [0.76561445 1.8719498  0.7916983  1.1042925  1.6807841 ]\n",
      "   [0.66130275 0.7916983  0.9489753  1.2927866  0.9971596 ]\n",
      "   [1.049701   1.1042925  1.2927866  1.8712728  1.492668  ]\n",
      "   [1.0571702  1.6807841  0.9971596  1.492668   1.8483708 ]]]\n",
      "\n",
      "\n",
      " [[[0.67231977 0.56260306 0.351696   0.91548496 0.62634295]\n",
      "   [0.56260306 1.5414855  0.40454924 0.8456847  0.4094615 ]\n",
      "   [0.351696   0.40454924 0.35396385 0.60876805 0.5360521 ]\n",
      "   [0.91548496 0.8456847  0.60876805 1.7189244  1.1863383 ]\n",
      "   [0.62634295 0.4094615  0.5360521  1.1863383  0.99793386]]\n",
      "\n",
      "  [[1.3067545  1.8955858  0.4978571  1.4108964  1.7713434 ]\n",
      "   [1.8955858  2.843541   0.8009552  2.2765472  2.7314198 ]\n",
      "   [0.4978571  0.8009552  0.2988351  0.69316655 0.8047227 ]\n",
      "   [1.4108964  2.2765472  0.69316655 2.1488864  2.3142455 ]\n",
      "   [1.7713434  2.7314198  0.8047227  2.3142455  2.6938558 ]]]], shape=(2, 2, 5, 5), dtype=float32)\n",
      "(2, 2, 5, 5)\n",
      "(2, 1, 5, 5)\n",
      "(2, 2, 5, 5) tf.Tensor(\n",
      "[[[[ 1.0575931e+00 -1.0000000e+09 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 1.1385020e+00  1.9640099e+00 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 1.2981929e+00  1.9233187e+00  2.2276442e+00 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 9.9380332e-01  1.0093265e+00  1.1605769e+00  9.4334406e-01\n",
      "    -1.0000000e+09]\n",
      "   [ 1.3994931e+00  1.7292845e+00  1.9642816e+00  1.3207018e+00\n",
      "     2.1967125e+00]]\n",
      "\n",
      "  [[ 7.4074578e-01 -1.0000000e+09 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 7.6561445e-01  1.8719498e+00 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 6.6130275e-01  7.9169828e-01  9.4897532e-01 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 1.0497010e+00  1.1042925e+00  1.2927866e+00  1.8712728e+00\n",
      "    -1.0000000e+09]\n",
      "   [ 1.0571702e+00  1.6807841e+00  9.9715960e-01  1.4926680e+00\n",
      "     1.8483708e+00]]]\n",
      "\n",
      "\n",
      " [[[ 6.7231977e-01 -1.0000000e+09 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 5.6260306e-01  1.5414855e+00 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 3.5169601e-01  4.0454924e-01  3.5396385e-01 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 9.1548496e-01  8.4568471e-01  6.0876805e-01  1.7189244e+00\n",
      "    -1.0000000e+09]\n",
      "   [ 6.2634295e-01  4.0946150e-01  5.3605211e-01  1.1863383e+00\n",
      "     9.9793386e-01]]\n",
      "\n",
      "  [[ 1.3067545e+00 -1.0000000e+09 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 1.8955858e+00  2.8435409e+00 -1.0000000e+09 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 4.9785709e-01  8.0095518e-01  2.9883510e-01 -1.0000000e+09\n",
      "    -1.0000000e+09]\n",
      "   [ 1.4108964e+00  2.2765472e+00  6.9316655e-01  2.1488864e+00\n",
      "    -1.0000000e+09]\n",
      "   [ 1.7713434e+00  2.7314198e+00  8.0472273e-01  2.3142455e+00\n",
      "     2.6938558e+00]]]], shape=(2, 2, 5, 5), dtype=float32)\n",
      "Attention weights are:\n",
      "(2, 2, 5, 5)\n",
      "Output is:\n",
      "(2, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "y = tf.random.uniform((2, 5, 10))  # (batch_size, encoder_sequence, d_model)\n",
    "print(y)\n",
    "print_out(y,y,y,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [0.5 0.  0.5]], shape=(3, 3), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[100.    5.    1. ]\n",
      " [ 10.    0.    7. ]\n",
      " [ 50.5   2.5   3. ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,0,10],\n",
    "                      [0,10,0]\n",
    "                      ], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0,5],\n",
    "                      [  10,0,7],\n",
    "                      [ 100,5,1]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "temp_q = tf.constant([[0, 10, 0],\n",
    "                     [0, 0, 10],\n",
    "                     [10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0.]], shape=(1, 3), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.  7.]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.  0.5]], shape=(1, 3), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[50.5  2.5  3. ]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  1.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.5 0.  0.5]], shape=(3, 3), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[ 10.    0.    7. ]\n",
      " [100.    5.    1. ]\n",
      " [ 50.5   2.5   3. ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "Multi-head attention consists of four parts:\n",
    "*    Linear layers and split into heads.\n",
    "*    Scaled dot-product attention. Dimension= (batch_size,number_of_heads,number_of_tokens,depth) \n",
    "*    Concatenation of heads.\n",
    "*    Final linear layer.\n",
    "*    $h=NumberOfHeads$\n",
    "*    $depth = \\frac{EmbeddingSize}{NumberOfHeads}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8, 40, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(32), Dimension(40), Dimension(512)]),\n",
       " TensorShape([Dimension(32), Dimension(8), Dimension(40), Dimension(40)]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((32, 40, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to recombined the local results of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(32), Dimension(40), Dimension(512)])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((32, 40, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 7. Encoder Layer <h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multihead ---> dropout ---> residual addition + layer normalization ----> point wise ffn ---> dropout ---> residual addition + layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(43), Dimension(512)])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 8. Decoder Layer <h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer encompasses the different modules needed to form a decoder layer. The call method, in addition of the output sentence appropriatly masked, needs the encoder output for key query values in the second attention block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(50), Dimension(512)])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two class are used to control the Decoder and Encoder modules. It is assumed that several Encoder layer and several decoder layers can be stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "           maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, \n",
    "       look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(64), Dimension(26), Dimension(512)]),\n",
       " TensorShape([Dimension(64), Dimension(8), Dimension(26), Dimension(62)]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 9. Full Transformer Module <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class just focus on creating the Transformer module.The call method return the output and the attention weights of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "        \n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(64), Dimension(36), Dimension(8000)])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Encoder)          multiple                  10656768  \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  12504064  \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             multiple                  4104000   \n",
      "=================================================================\n",
      "Total params: 27,264,832\n",
      "Trainable params: 27,264,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 10. Prepare model for training <h1>\n",
    "\n",
    "<h2> 10.1 Parameters Specification <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10.2 Custom optimizer: Special learning rate with Adam <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10.3 Loss Function <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done in two step: Computing the categorical cross antropy  and making sure that the netowrk doesn't care about masked prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10.4 Create Model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10.5 Create Masks <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10.6 Create Checkpoints <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10.7 Create a training step function <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "        train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10.8 Train the model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transformer_1/encoder_2/encoder_layer_5/multi_head_attention_16/add:0\", shape=(?, 8, ?, ?), dtype=float32)\n",
      "Tensor(\"transformer_1/encoder_2/encoder_layer_6/multi_head_attention_17/add:0\", shape=(?, 8, ?, ?), dtype=float32)\n",
      "Tensor(\"transformer_1/encoder_2/encoder_layer_7/multi_head_attention_18/add:0\", shape=(?, 8, ?, ?), dtype=float32)\n",
      "Tensor(\"transformer_1/encoder_2/encoder_layer_8/multi_head_attention_19/add:0\", shape=(?, 8, ?, ?), dtype=float32)\n",
      "Tensor(\"transformer_1/decoder_2/decoder_layer_5/multi_head_attention_20/add:0\", shape=(?, 8, ?, ?), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x2b659856b2b0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adbadre/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 531, in __del__\n",
      "    handle=self._handle, deleter=self._deleter)\n",
      "  File \"/home/adbadre/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 787, in delete_iterator\n",
      "    deleter)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0;34m\"RestoreV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m         tensor_names, shape_and_slices, \"dtypes\", dtypes)\n\u001b[0m\u001b[1;32m   1673\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-6d658aa076ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# inp -> portuguese, tar -> english\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    357\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    358\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 359\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1542\u001b[0m         self._function_attributes)\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                           converted_func)\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                 ), args, kwargs)\n\u001b[0m\u001b[1;32m    704\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mStackTraceMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCurrentModuleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpgijl8tfo.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(inp, tar)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtar_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gradient'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptional_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             ), args, kwargs)\n\u001b[0m\u001b[1;32m    167\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mStackTraceMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCurrentModuleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpokee7a8f.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decoder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_ahead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_layer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptional_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             ), args, kwargs)\n\u001b[0m\u001b[1;32m    167\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mStackTraceMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCurrentModuleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmppszgqm2g.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decoder_layer{}_block2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, init_state)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_py_for_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(iter_, extra_test, body, init_state)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mextra_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmppszgqm2g.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(loop_vars, x_1)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_ahead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decoder_layer{}_block1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decoder_layer{}_block2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptional_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             ), args, kwargs)\n\u001b[0m\u001b[1;32m    167\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mStackTraceMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCurrentModuleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpr9s2deyr.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mattn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropout1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layernorm1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mattn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_block2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mha2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mattn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropout2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layernorm2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptional_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             ), args, kwargs)\n\u001b[0m\u001b[1;32m    167\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mStackTraceMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCurrentModuleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmp9pas3ny3.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1024\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m           trainable=True)\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;31m# there is nothing to restore.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         checkpoint_initializer = self._preload_simple_restoration(\n\u001b[0;32m--> 694\u001b[0;31m             name=name, shape=shape)\n\u001b[0m\u001b[1;32m    695\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0mcheckpoint_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_preload_simple_restoration\u001b[0;34m(self, name, shape)\u001b[0m\n\u001b[1;32m    759\u001b[0m         key=lambda restore: restore.checkpoint.restore_uid)\n\u001b[1;32m    760\u001b[0m     return CheckpointInitialValue(\n\u001b[0;32m--> 761\u001b[0;31m         checkpoint_position=checkpoint_position, shape=shape)\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_track_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_position, shape)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVARIABLE_VALUE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# We need to set the static shape information on the initializer if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mvalue_tensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m               \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m               \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m               name=\"%s_checkpoint_read\" % (serialized_tensor.name,))\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Copy the value to the current device if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mvalue_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mserialized_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         return restore_v2_eager_fallback(\n\u001b[1;32m   1677\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m   1679\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[1;32m   1727\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m   _result = _execute.execute(b\"RestoreV2\", len(dtypes), inputs=_inputs_flat,\n\u001b[0;32m-> 1729\u001b[0;31m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   1730\u001b[0m   _execute.record_gradient(\n\u001b[1;32m   1731\u001b[0m       \"RestoreV2\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                 ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 11. Evaluate and print results <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_pt.vocab_size]\n",
    "    end_token = [tokenizer_pt.vocab_size + 1]\n",
    "    \n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    decoder_input = [tokenizer_en.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer_en.vocab_size+1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    print(result)\n",
    "    predicted_sentence = tokenizer_en.decode([i for i in result if i < tokenizer_en.vocab_size])  \n",
    "    \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[8087   16   13    3  124  774   12 2224    1   12   98    3  124  774\n",
      "   12 2224    2 8088    2 8088    2 8088    2 8088    2 8088    2 8088\n",
      " 7863    6  161    2 8088    2 8088    2 8088    2 8088    2 8088], shape=(41,), dtype=int32)\n",
      "Input: este  o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first book i made , i did the first book i made . . . . . . of them . . . . .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b57539ff710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este  o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
